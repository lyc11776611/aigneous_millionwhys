# Automated Question Generation with Multi-Layer Validation

## ğŸ¯ Overview

This document describes the **automated 3-layer validation workflow** for creating scientifically accurate questions.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: Manual Review Agent (during generation)          â”‚
â”‚  â†“ Built into SKILL.md workflow                            â”‚
â”‚  â†“ AI reviews own content for scientific accuracy          â”‚
â”‚  â†“ Self-correction loop until HIGH confidence               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: Automated Structure Validation                   â”‚
â”‚  â†“ validate_facts.py                                        â”‚
â”‚  â†“ Checks format, lengths, consistency, red flags          â”‚
â”‚  â†“ BLOCKS if critical issues found                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: AI Fact-Check with Web Search                    â”‚
â”‚  â†“ ai_fact_check.py                                         â”‚
â”‚  â†“ Verifies facts against authoritative sources            â”‚
â”‚  â†“ Generates detailed fact-check report                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                 âœ… VALIDATED QUESTION
```

## ğŸ“‹ Complete Workflow

### When Creating New Questions

**Step 1: Generate Question (with Layer 1 validation)**

Use the curious-minds skill which includes built-in Review Agent:

```
User: "Generate 3 chemistry questions about cooking"

Skill:
  1. âœï¸  Generate question, choices, explanations
  2. ğŸ” LAYER 1: Review Agent activates
  3. âœ“  Fact-check scientific accuracy
  4. âœ“  Verify correct answer is correct
  5. âœ“  Check for misconceptions
  6. ğŸ”„ Self-correction loop if issues found
  7. âœ… Only accept HIGH confidence content
  8. ğŸ’¾ Save to chemistry.json
```

**Step 2: Auto-Validate (Layer 2 + 3)**

Immediately after saving, run automatic validation:

```bash
# Validate the file (from repository root)
python3 scripts/auto_validate.py chemistry.json --ai-check
```

This will:
- âœ“ **Layer 2**: Check structure, format, consistency
- âœ“ **Layer 3**: Generate AI fact-check prompts
- âš ï¸  BLOCK if critical issues found

**Step 3: AI Fact-Check (if needed)**

If Layer 3 prompts are generated, run them through Claude:

```bash
# Get fact-check prompt for specific question (from repository root)
python3 scripts/ai_fact_check.py --file chemistry.json --question chem_004
```

Copy the prompt â†’ Run through Claude with web search â†’ Review findings

**Step 4: Fix Issues (Self-Correction)**

If any layer found issues:

```
1. Review the issue details
2. Fix the question content
3. Re-run validation: python3 scripts/auto_validate.py chemistry.json
4. Repeat until âœ… PASSED
```

## ğŸ¤– Automatic Options

### Option 1: Git Pre-Commit Hook (Recommended)

Automatically validate before every commit:

```bash
# One-time setup (from repository root)
bash scripts/install_git_hook.sh

# Now validation runs automatically on commit
git add src/data/questions/chemistry.json
git commit -m "Add new questions"
# â†’ Validation runs automatically
# â†’ Commit blocked if issues found!
```

**Benefits:**
- âœ… Can't accidentally commit invalid questions
- âœ… Team members protected from mistakes
- âœ… Zero extra effort after setup

### Option 2: Watch Mode

Auto-validate whenever files change:

```bash
# Start watch mode (from repository root)
python3 scripts/auto_validate.py --watch

# Now edit src/data/questions/chemistry.json in another window
# â†’ Validation runs automatically on save!
```

**Benefits:**
- âœ… Immediate feedback while editing
- âœ… Catches issues in real-time
- âœ… Great for development

### Option 3: Validate All (Pre-Release)

Before releasing, validate everything:

```bash
# Validate all question files (from repository root)
python3 scripts/auto_validate.py --all

# With AI fact-check prompts
python3 scripts/auto_validate.py --all --ai-check
```

## ğŸ”§ Integration with Skill

The SKILL.md has been updated with the complete workflow:

### Updated Generation Process

```markdown
**Phase 1: Planning**
1. Ask user for topic, difficulty, count

**Phase 2: Generation**
2. Generate question, choices, explanations

**Phase 3: Layer 1 - Manual Review Agent (BUILT-IN)**
3. âœ“ Activate Review Agent
4. âœ“ Fact-check scientific accuracy
5. âœ“ Verify correct/wrong answers
6. âœ“ Check for misconceptions
7. ğŸ”„ Self-correction if needed
8. âœ… Only accept HIGH confidence

**Phase 4: Save & Auto-Validate**
9. ğŸ’¾ Save to .json file
10. ğŸ¤– Auto-run Layer 2 validation (structure)
11. ğŸ“Š Report: PASSED or issues found

**Phase 5: Layer 3 - AI Fact-Check (if requested)**
12. ğŸ§  Generate fact-check prompts
13. ğŸ” User runs through Claude with web search
14. âœ… Verify against authoritative sources

**Phase 6: Self-Correction (if needed)**
15. ğŸ”„ Fix any issues found
16. ğŸ” Re-validate until PASSED
17. âœ… Final validation before release
```

## ğŸ“Š Validation Criteria

### Layer 1: Manual Review Agent (in SKILL.md)

**Checks:**
- âœ“ Scientific accuracy of correct answer
- âœ“ Wrong answer explanations are accurate
- âœ“ No common misconceptions reinforced
- âœ“ Current scientific understanding
- âœ“ No contradictions

**Confidence Levels:**
- âœ… HIGH: Established science, verified facts â†’ ACCEPT
- âš ï¸ MEDIUM: Generally accepted â†’ NEEDS MORE REVIEW
- âŒ LOW: Uncertain/controversial â†’ REJECT

### Layer 2: Automated Structure Validation

**Checks:**
- âœ“ Valid JSON format
- âœ“ All required fields present
- âœ“ Character limits (mobile optimization)
- âœ“ Explanation format (Correct!/Wrong.)
- âœ“ Logical consistency
- âœ“ Red flag words (always, never, proven)
- âœ“ Category-specific misconceptions

**Severity Levels:**
- ğŸ”´ CRITICAL: BLOCKS validation â†’ MUST FIX
- ğŸŸ¡ WARNING: Should review â†’ RECOMMENDED FIX
- â„¹ï¸ INFO: Nice to know â†’ OPTIONAL

### Layer 3: AI Fact-Check with Web Search

**Checks:**
- âœ“ Scientific claims verified against web sources
- âœ“ Authoritative sources consulted (NASA, NIH, Wikipedia, journals)
- âœ“ Numerical values verified (speeds, percentages, temperatures)
- âœ“ Current information (not outdated)
- âœ“ No misconceptions created

**Sources by Category:**
- **Astronomy**: NASA, ESA, astronomical databases
- **Chemistry**: Chemistry journals, educational sites
- **Biology**: NIH, medical sites, biology textbooks
- **Physics**: Physics resources, verified sources
- **Psychology**: Peer-reviewed research, APA resources

## ğŸ“ Best Practices

### For Question Authors

1. **Always use the skill** - it includes Layer 1 validation
2. **Run auto-validation** after creating questions
3. **Fix critical issues** immediately (can't proceed without)
4. **Review warnings** for quality improvement
5. **Fact-check with web search** for high-stakes content
6. **Re-validate after fixes** to ensure correctness

### For Teams

1. **Install git hook** - protects whole team
2. **Code review** - second pair of eyes
3. **Regular validation** - run `--all` before releases
4. **Track metrics** - monitor quality over time
5. **Update validators** - add new checks as needed

### For Specific Topics

**High-Risk Topics** (require extra validation):
- Medical/health information
- Physics formulas and calculations
- Chemical reactions
- Astronomical data
- Economic principles

**For these:**
- âœ… Always run Layer 3 AI fact-check
- âœ… Consider expert review
- âœ… Add source citations

## ğŸš€ Quick Reference

### Common Commands

```bash
# All commands run from repository root

# Validate single file
python3 scripts/auto_validate.py chemistry.json

# Validate with AI fact-check
python3 scripts/auto_validate.py chemistry.json --ai-check

# Validate all files
python3 scripts/auto_validate.py --all

# Watch mode (auto-validate on changes)
python3 scripts/auto_validate.py --watch

# Install git hook (one-time)
bash scripts/install_git_hook.sh

# Run fact-check on specific question
python3 scripts/ai_fact_check.py --file chemistry.json --question chem_001
```

### Exit Codes

- `0`: All validations passed âœ…
- `1`: Critical issues found âŒ

### Bypass (Emergency Only)

```bash
# Skip validation in git commit (NOT RECOMMENDED)
git commit --no-verify

# Run without blocking on critical issues
python3 scripts/auto_validate.py --no-strict chemistry.json
```

## ğŸ“ˆ Quality Metrics

Track these over time:

- **Pass Rate**: % of questions passing all layers first try
- **Critical Issue Rate**: Critical issues per 100 questions
- **Fact-Check Success**: % passing AI fact-check
- **Common Issues**: Which validators trigger most often

## ğŸ”® Future Enhancements

Potential additions to the validation system:

1. **Source Citation Tracking**: Require sources for facts
2. **Plagiarism Detection**: Check against existing questions
3. **User Testing**: Track which questions confuse users
4. **Difficulty Calibration**: Verify difficulty ratings with data
5. **Translation Validation**: Ensure CN/EN equivalence
6. **Accessibility Checks**: Screen reader compatibility
7. **A/B Testing**: Compare question variations

---

## ğŸ“ Getting Help

**Validation failed and not sure why?**

1. Read the detailed error message
2. Check against SKILL.md requirements
3. Run fact-check: `python3 scripts/ai_fact_check.py --file [file]`
4. Review with Claude using the generated prompt
5. Fix and re-validate

**Need to add custom validation?**

Edit `validate_facts.py` and add to:
- `_check_accuracy_markers()` for red flags
- `_get_manual_verification_notes()` for category checks
- `misconception_checks` dict for topic-specific issues

---

**Last Updated**: 2025-11-18
**Version**: 1.0
**Status**: Ready for Production âœ…
